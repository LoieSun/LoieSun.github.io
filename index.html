<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Loie Sun</title>
  
  <meta name="author" content="Loie Sun">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:65%;vertical-align:middle">
              <p style="text-align:center">
                <name>Sun Luoyi (孙络祎)</name>
		<br>
              </p>
              <p>I am a second-year master in <a href="https://sfa.shu.edu.cn/">Shanghai Film Academy</a>, <a href="https://www.shu.edu.cn/">Shanghai University</a>, supervised by Prof. Zhifeng Xie. 
		       I earned my Bachelor degree from <a href="http://www.sei.ynu.edu.cn/">School of Software</a>, <a href="http://www.ynu.edu.cn/">Yunnan University</a>.
		</p>
	      <p>
              My research interests include deep learning, cross-modal generation and music generation.
              </p>
              <p>
              I am actively seeking a PhD position.
              </p>
              <p style="text-align:center">
                <a href="Loie.pdf">CV</a> &nbsp/&nbsp
                <a href="sunluoyi@shu.edu.cn/"> Email: sunluoyi@shu.edu.cn </a> &nbsp/&nbsp
    		<a href="https://github.com/LoieSun"> GitHub </a> &nbsp/&nbsp
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/loie.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/loie.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
	<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Research</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
		
	   <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/sound_generation.png" alt="soundgeneration" width="160" height="100">
                </td>
                <td width="75%" valign="middle">
                  <a href="data/Sound Generation Method based on Timing-aligned Visual Feature Mapping.pdf">
                    <papertitle> Sound Generation Method based on Timing-aligned Visual Feature Mapping </papertitle>
                  </a>
                  <br>
		 Zhifeng Xie, <b>Luoyi Sun</b>, Yuzhou Sun, Chunpeng Yu, Lizhang Ma
                  <br>
                  <em>ChinaMM</em>, 2022 &nbsp 
                  <br>
                  <a href="data/Sound Generation Method based on Timing-aligned Visual Feature Mapping.pdf">pdf</a> 
                  <p></p>
                  <p>New framework for high-quality sound generation, matching to silent videos in content and timing alignment.</p>
                </td>
              </tr>
	     <tr>
		     
	     <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/SOD.png" alt="sod" width="160" height="100">
                </td>
                <td width="75%" valign="middle">
                  <a href="https://ieeexplore.ieee.org/abstract/document/9506100">
                    <papertitle> Multi-Scale Graph Convolutional Interaction Network For Salient Object Detection </papertitle>
                  </a>
                  <br>
		Wenqi Che, <b>Luoyi Sun</b>, Zhifeng Xie, Youdong Ding, Kanli Han
                  <br>
                  <em>ICIP</em>, 2021 &nbsp 
                  <br>
                  <a href="data/Multi-Scale_Graph_Convolutional_Interaction_Network_For_Salient_Object_Detection.pdf">pdf</a> 
                  <p></p>
                  <p>Proposed the multi-scale graph convolutional interaction network (MGCINet), and get the SOTA on five benchmark datasets. </p>
                </td>
              </tr>
	
     
        </tbody></table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
        <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Teaching/Invited Talks</heading>
            <p>
            "Multimodality for Video Understanding", <a href="https://sites.google.com/view/aisummerschool2020">Google Research India AI Summer School</a>, 2020 [<a href="https://docs.google.com/presentation/d/1J4AVI9S1KBFZyGiBdFJn64k2BRFhlRRngd8r262Xo8g/edit?usp=sharing">slides</a>] </br>
            "Learning joint representations for visual and language tasks", <a href="https://multimodal-knowledge-discovery.github.io/">Online Multimodal Knowledge Discovery Tutorial</a>, ICDM 2020
            "Applications of Machine Learning", Oxford University MPLS DTC on Statistics and Data Mining, 2020 [<a href="https://docs.google.com/presentation/d/1XgNYFLNwlODst7LiFuaof2F9uuNcv3ZdwdiyXrCT1-A/edit?usp=sharing">slides</a>]
            </p>
          </td>
        </tr>
      </tbody></table>
    





        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Service</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <th style="padding:20px;width:25%;vertical-align:middle;text-align: center">
                      <img src="images/video-pent-logo.svg" alt="video-pent" width="100" height="80" class="center">
            </th>
           <td width="75%" valign="center">
            <strong> The End-of-End-to-End: </strong>  A Video Understanding Pentathlon @ CVPR 2020
            </br>
            <a href="https://arxiv.org/pdf/2008.00744.pdf">report</a> /
            <a href="https://www.robots.ox.ac.uk/~vgg/challenges/video-pentathlon/challenge.html">challenge</a> /
            <a href="https://www.robots.ox.ac.uk/~vgg/challenges/video-pentathlon/">workshop</a> 	/
            <a href="https://www.youtube.com/watch?v=L2rff2mu1gE">recording</a> 	
            </br>										 
            </br>
    
            </td>
            </tr>

          <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/voxsrc.png" alt="voxsrc" width="150" height="50">
        </td>
       <td width="75%" valign="center">
	      <strong> VoxSRC: </strong> VoxCeleb Speaker Recognition Challenge @ INTERSPEECH 
        </br>
        [2021]
<a href="https://arxiv.org/pdf/2201.04583.pdf">report</a> / 	
	<a href="http://www.robots.ox.ac.uk/~vgg/data/voxceleb/competition2021.html">challenge</a> /
	<a href="http://www.robots.ox.ac.uk/~vgg/data/voxceleb/interspeech2021.html">workshop</a> /
        <a href="http://www.robots.ox.ac.uk/~vgg/data/voxceleb/index.html">data</a>													              
       </br>
        [2020]
        <a href="https://arxiv.org/pdf/2012.06867.pdf">report</a> /
	<a href="http://www.robots.ox.ac.uk/~vgg/data/voxceleb/competition2020.html">challenge</a> /
	<a href="http://www.robots.ox.ac.uk/~vgg/data/voxceleb/interspeech2020.html">workshop</a> /
        <a href="http://www.robots.ox.ac.uk/~vgg/data/voxceleb/index.html">data</a>													              
       </br>										 
        [2019]
        <a href="http://www.robots.ox.ac.uk/~vgg/data/voxceleb/files/VoxSRC19.pdf">report</a> /
	      <a href="http://www.robots.ox.ac.uk/~vgg/data/voxceleb/competition2019.html">challenge</a> /
	      <a href="http://www.robots.ox.ac.uk/~vgg/data/voxceleb/interspeech2019.html">workshop</a> /
	      <a href="http://www.robots.ox.ac.uk/~vgg/data/voxceleb/index.html">data</a>													               </br>										 
	      </br>

        </td>
        </tr>

        <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/wicv.png" alt="wicv" width="150" height="50">
      </td>
      <td width="75%" valign="center">
        <strong> WICV: </strong> Women in Computer Vision Workshop @ CVPR
      </br>
      [2020]
      <a href="https://sites.google.com/view/wicvworkshop-cvpr2020/">website</a> /
      <a href="https://twitter.com/wicvworkshop?lang=en">twitter</a>													     									 
      </br>
        [2019]
	      <a href="http://openaccess.thecvf.com/content_CVPRW_2019/html/WiCV/Amerini_WiCV_2019_The_Sixth_Women_In_Computer_Vision_Workshop_CVPRW_2019_paper.html">report</a> /
	      <a href="https://wicvworkshop.github.io/CVPR2019/index.html">website</a> /
	      <a href="https://twitter.com/wicvworkshop?lang=en">twitter</a>													         </br>										 
        </br>
        </td>
        </tr>
        <tr>
            <td style="padding:20px;width:25%;vertical-align:middle;text-align: center">
                <img src="images/reviewer.jpg" alt="review" width="150" height="70" >
      </td>
          <td>
              <strong> Reviewer </strong>: CVPR, ECCV, ICCV, BMVC, NeurIps, ICML, AAAI, IEEE Triple Access
              <br>

            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                 Template from <a href="https://jonbarron.info/">Jon Barron</a>. 
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
