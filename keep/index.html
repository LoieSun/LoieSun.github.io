

<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<style type="text/css">
  @font-face {
   font-family: 'Avenir Book';
   src: url("./fonts/Avenir_Book.ttf"); /* File to be stored at your site */
   }

  body {
    font-family: "Avenir Book", "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight:300;
    font-size:14px;
    margin-left: auto;
    margin-right: auto;
    width: 800px;
  }
  h1 {
    font-weight:300;
  }
  h2 {
    font-weight:300;
  }

  p {
    font-weight:300;
    line-height: 1.4;
  }

  code {
    font-size: 0.8rem;
    margin: 0 0.2rem;
    padding: 0.5rem 0.8rem;
    white-space: nowrap;
    background: #efefef;
    border: 1px solid #d3d3d3;
    color: #000000;
    border-radius: 3px;
  }

  pre > code {
    display: block;
    white-space: pre;
    line-height: 1.5;
    padding: 0;
    margin: 0;
  }

  pre.prettyprint > code {
    border: none;
  }


  .container {
        display: flex;
        align-items: center;
        justify-content: center
  }
  .image {
        flex-basis: 40%
  }
  .text {
        padding-left: 20px;
        padding-right: 20px;
  }
  .grid-container {
      display: grid;
      grid-template-columns: auto auto auto;
      grid-gap: 10px;
      background-color: #FFFFFF;
      padding: 10px;
}

  .disclaimerbox {
    background-color: #eee;
    border: 1px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
    padding: 20px;
  }

  video.header-vid {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  img.header-img {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  img.rounded {
    border: 0px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;

  }

  a:link,a:visited
  {
    color: #1367a7;
    text-decoration: none;
  }
  a:hover {
    color: #208799;
  }

  td.dl-link {
    height: 160px;
    text-align: center;
    font-size: 22px;
  }

  .layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
            0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
            5px 5px 0 0px #fff, /* The second layer */
            5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
            10px 10px 0 0px #fff, /* The third layer */
            10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
            15px 15px 0 0px #fff, /* The fourth layer */
            15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
            20px 20px 0 0px #fff, /* The fifth layer */
            20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
            25px 25px 0 0px #fff, /* The fifth layer */
            25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
    margin-left: 10px;
    margin-right: 45px;
  }


  .layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
            0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
            5px 5px 0 0px #fff, /* The second layer */
            5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
            10px 10px 0 0px #fff, /* The third layer */
            10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
    margin-top: 5px;
    margin-left: 10px;
    margin-right: 30px;
    margin-bottom: 5px;
  }

  .vert-cent {
    position: relative;
      top: 50%;
      transform: translateY(-50%);
  }

  hr
  {
    border: 0;
    height: 1px;
    background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
  }
</style>

  <title>Auto-ACD</title>
</head>

<body data-new-gr-c-s-check-loaded="14.1093.0" data-gr-ext-installed="">
  <br>
  <center>
  <span style="font-size:36px">A Large-scale Dataset for Audio-Language Representation Learning</span><br><br><br>
  </center>
  <table align="center" width="800px">
            <tbody><tr>
                    <td align="center" width="175px">
              <center>
                <span style="font-size:16px">Luoyi Sun</a><sup>1,3</sup></span>
                </center>
                </td>
                    <td align="center" width="175px">
              <center>
                <span style="font-size:16px">Xuenan Xu<sup>2</sup></span>
                </center>
              </td>
                    
                    <td align="center" width="225px">
              <center>
                <span style="font-size:16px">Mengyue Wu</a><sup>2 <img class="round" style="width:20px" src="./resources/corresponding_fig.png"></sup></span>
                </center>
                </td>
                    <td align="center" width="225px">
              <center>
                <span style="font-size:16px"><a href="https://weidixie.github.io/">Weidi Xie</a><sup>1, 3 <img class="round" style="width:20px" src="./resources/corresponding_fig.png"></sup></span>
                </center>            
            
          </td></tr>
        </tbody></table><br>
  
  <table align="center" width="700px">
            <tbody><tr>
                    <td align="center" width="50px">
              <center>
                    <span style="font-size:16px"></span>
                </center>
                </td>
                    <td align="center" width="350px">
              <center>
                    <span style="font-size:16px"><sup>1</sup>CMIC & <sup>2</sup>X-LANCE Shanghai Jiao Tong University</span>
                </center>
                </td>
                    <td align="center" width="250px">
              <center>
                    <span style="font-size:16px"><sup>3</sup>Shanghai AI Lab</span>
                </center>
                </td>
        </tr></tbody></table>

   <br>
  <table align=center width=500px>
        <tr>
          <td align=center width=500px>
            <center>
              <span style="font-size:22px">
                <span style="font-size:20px">Accepted by ACM MM 2024</span>
              </span>
            </center>
          </td>
        </tr>
      </table> 
  <br><hr>
  <table align="center" width="750px">
            <tbody><tr>
              <td align="center" width="180px">
                <center>
                  <br>
                  <span style="font-size:17px">Code
                    <a href="https://github.com/LoieSun/Auto-ACD"> [GitHub]</a>
                  </span>
                </center>
              </td>

              <td align="center" width="180px">
                <center>
                  <br>
                  <span style="font-size:17px">
                    Paper <a href="https://arxiv.org/abs/2309.11500"> [arXiv]</a>
<!--                     Paper  -->
                  </span>
                </center>
              </td>

              <td align="center" width="180px">
                <center>
                  <br>
                  <span style="font-size:17px">
                    Cite <a href="./resources/bibtex.txt"> [BibTeX]</a>
<!--                     Cite  -->
                  </span>
                </center>
              </td>

              <td align="center" width="210px">
                <center>
                  <br>
                  <span style="font-size:17px">
                    Dataset <a href="https://huggingface.co/datasets/Loie/Auto-ACD"> [HuggingFace]</a>
                  </span>
                </center>
              </td>
            </tr></tbody>
      </table>
  
      <br><hr>
      
        <p style="text-align:justify; text-justify:inter-ideograph;"><left>
          <div class="container">
        <div class="image" width="500px">
          <center><p><img class="center" src="./resources/analysis.png" width="450px"></p></center>
        </div>
          <p style="text-align:justify; text-justify:inter-ideograph;"><left></left>
          We present an innovative and <strong>automatic</strong> audio caption generation pipeline(<strong>*</strong>), construct a large-scale, high-quality, audio-language dataset, named as <strong>Auto-ACD</strong>, comprising over <strong>1.9M </strong> audio-text pairs. 
          As shown in the left figure, The text descriptions in Auto-ACD contain <strong>long texts (18 words)</strong> and <strong>diverse vocabularies (23K)</strong>, and provide information about the <strong>surrounding auditory environment</strong>(data point with <strong>shadow</strong>) in which sounds take place.
        </left></p>  
      </div>
      </left></p>
      <hr>
      <br>


      <center> <h2> Preview </h2> </center>
       <div class="grid-container">
        <div>
          <video width="250"  controls>
            <source src="resources/D6_A50my-R8_000002.mp4" type="video/mp4">
            <source src="resources/D6_A50my-R8_000002.ogg" type="video/ogg">
          </video>
          <div class="text" width="270px"> 
            <p style="text-align:justify; text-justify:inter-ideograph;">
              <left>
                A singing bowl resonates with a gentle gong sound, accompanied by soft music playing in a church.
            </left></p>
          </div>
        </div>
        
        <div>
          <video width="250"  controls>
            <source src="resources/nKtGjo-9p4M_000030.mp4" type="video/mp4">
            <source src="resources/nKtGjo-9p4M_000030.ogg" type="video/ogg">
          </video>
          <div class="text" width="270px"> 
            <p style="text-align:justify; text-justify:inter-ideograph;">
              <left>
                A melodic accordion tune fills the air as the musician plays in a music studio, creating a pleasant ambiance.
            </left></p>
          </div>
        </div>

        <div>
          <video width="250"  controls>
            <source src="resources/boWKyNs9gQs_000140.mp4" type="video/mp4">
            <source src="resources/boWKyNs9gQs_000140.ogg" type="video/ogg">
          </video>
          <div class="text" width="270px"> 
            <p style="text-align:justify; text-justify:inter-ideograph;">
              <left>
                A train horn blares as a train approaches, creating a loud and powerful sound in a railway environment.
            </left></p>
          </div>
        </div>

        <div>
          <video width="250"  controls>
            <source src="resources/BPyI5tsSgLA_000228.mp4" type="video/mp4">
            <source src="resources/BPyI5tsSgLA_000228.ogg" type="video/ogg">
          </video>
          <div class="text" width="270px"> 
            <p style="text-align:justify; text-justify:inter-ideograph;">
              <left>
                Rain falls hard on a surface as people talk in the distance, creating a soothing ambiance of a rainy day.
            </left></p>
          </div>
        </div>
        
        <div>
          <video width="250"  controls>
            <source src="resources/d5itsbzJF3s_000030.mp4" type="video/mp4">
            <source src="resources/d5itsbzJF3s_000030.ogg" type="video/ogg">
          </video>
          <div class="text" width="270px"> 
            <p style="text-align:justify; text-justify:inter-ideograph;">
              <left>
                Sheep bleat in the distance as people talk faintly, creating a pastoral atmosphere in a wheat field.
            </left></p>
          </div>
        </div>

        <div>
          <video width="250"  controls>
            <source src="resources/68v05KO6CVg_000021.mp4" type="video/mp4">
            <source src="resources/68v05KO6CVg_000021.ogg" type="video/ogg">
          </video>
          <div class="text" width="270px"> 
            <p style="text-align:justify; text-justify:inter-ideograph;">
              <left>
                An emergency vehicle siren blares loudly as a fire engine speeds through the city streets, signaling an urgent situation.
            </left></p>
          </div>
        </div>

        <div>
          <video width="250"  controls>
            <source src="resources/rQwOIwziqwk_000100.mp4" type="video/mp4">
            <source src="resources/rQwOIwziqwk_000100.ogg" type="video/ogg">
          </video>
          <div class="text" width="270px"> 
            <p style="text-align:justify; text-justify:inter-ideograph;">
              <left>
                The motorcycle engine revs up and down while driving through a residential neighborhood, accompanied by some speech and light engine sounds.
            </left></p>
          </div>
        </div>
        
        <div>
          <video width="250"  controls>
            <source src="resources/hel2rE-Ju_Y_000031.mp4" type="video/mp4">
            <source src="resources/hel2rE-Ju_Y_000031.ogg" type="video/ogg">
          </video>
          <div class="text" width="270px"> 
            <p style="text-align:justify; text-justify:inter-ideograph;">
              <left>
                Bird wings flap as rustling and birds chirping in the background create a serene ambiance in a garden.
            </left></p>
          </div>
        </div>

        <div>
          <video width="250"  controls>
            <source src="resources/0MrdMvs6J2o_000001.mp4" type="video/mp4">
            <source src="resources/0MrdMvs6J2o_000001.ogg" type="video/ogg">
          </video>
          <div class="text" width="270px"> 
            <p style="text-align:justify; text-justify:inter-ideograph;">
              <left>
                A roaring crowd erupts in cheers and battle cries, creating an electrifying atmosphere during a lively event.
            </left></p>
          </div>
        </div>

          </video>
        </div> 
    </div>
      <br>
      <hr>
      <br>
  

      <center><h2> Abstract </h2> </center>
      <p style="text-align:justify; text-justify:inter-ideograph;">
      </p><div class="container">
        <div class="text" width="400px"> 
          <p style="text-align:justify; text-justify:inter-ideograph;">
            <left>
              The AI community has made significant strides in developing powerful foundation models, driven by large-scale multimodal datasets. 
              However, in the audio representation learning community, the present audio-language datasets suffer from limitations such as insufficient volume, simplistic content, and arduous collection procedures. 
              To tackle these challenges, we present an innovative and automatic audio caption generation pipeline based on a series of public tools or APIs, and construct a large-scale, high-quality, audio-language dataset, named as Auto-ACD, comprising over 1.9M audio-text pairs. 
              To demonstrate the effectiveness of the proposed dataset, we train popular models on our dataset and show performance improvement on various downstream tasks, namely, audio-language retrieval, audio captioning, environment classification. 
              In addition, we establish a novel test set and provide a benchmark for audio-text tasks. 
          </left></p>
        </div>
      </div>
      <br>
      <hr>
      <br>
      <center> <h2> Dataset Pipeline </h2> </center>
      <p><img class="left" src="./resources/pipeline.png" width="800px"></p>
      <p style="text-align:justify; text-justify:inter-ideograph;"><left>
        This figure illustrates the pipeline we employ for the data collection process, we employ a range of publicly available tools or APIs across the general AI community, <i>e.g.</i>, vision, language and audio models,
        to generate comprehensive language descriptions for the audio tracks of the given video datasets,  <i>e.g.</i>, AudioSet, VGGSound. 
         </left></p>
      
      <br>
      <hr>
      <br>
      <center> <h2> Architecture </h2> </center>
      <p><img class="left" src="./resources/architecture.png" width="800px"></p>
      <p style="text-align:justify; text-justify:inter-ideograph;"><left>
        The overview of our architectures. 
        The <strong>left</strong> figure shows the audio-language retrieval model, we employ the pre-trained HTSAT as the audio encoder, and the pre-trained RoBERTa as the language encoder, both encoders were initialised from the pre-trained CLAP model.
        The <strong>right</strong> figure shows the automatic audio captioning model, we adopt a lightweight audio captioning model, where both the audio backbone and language model (GPT-2) are fixed, and only a mapping network is train.
         </left></p>
      
      <br>
      <hr>
      <br>


      <center><h2>Protocol-I: Audio-language Retrieval</h2></center>
      <p style="text-align:justify; text-justify:inter-ideograph;"><left>
      To validate the efficacy of our proposed dataset, we train an audio-language model with standard contrastive learning. The results showcase,
        (i) training on Auto-ACD<sub>VS</sub> dataset leads to a significant improvement in Recall@<i>k</i>. (ii) training on Auto-ACD leads to a remarkable performance gain. 
        (iii) on the Auto-ACD benchmark, which contains more diverse lexicon and abundant language description, training on Auto-ACD datasets significantly out performs the model trained on Laion-Audio-630K.
      </left></p>
      <p><img class="center" src="./resources/retrieval.png" width="800px"></p>

   
      <br>
      <hr>
      <br>

      <center><h2>Protocol-II: Automatic Audio Captioning</h2></center>
      <p><b>Comparison with CLAP on Clotho and Auto-ACD. </b> </p>
      <div class="container">
        <div class="image" width="400px">
          <center><p><img class="center" src="./resources/captioning.png" width="375px"></p></center>
        </div>
        <div class="text" width="400px"> 
          <p style="text-align:justify; text-justify:inter-ideograph;"><left>
           We use audio captioning to demonstrate the effectiveness of our pretrained audio backbone. The results show improved performance across all evaluation metrics than baseline.
             And the performance of baseline approach  oversees a sharp decrease on Auto-ACD.
            </left></p>
        </div>
      </div>
      <br>
      <hr>
      <br>

      <center><h2>Protocol-III:Environment Classification</h2></center>
      
      <p><b>Comparison with CLAP on DCASE 2020 Mobile and AudioSet Env.</b> </p>
      <div class="container">
        <div class="image" width="400px">
          <center><p><img class="center" src="./resources/env.png" width="375px"></p></center>
        </div>
        <div class="text" width="400px"> 
          <p style="text-align:justify; text-justify:inter-ideograph;"><left></left>
          We conduct environment classification, the results indicate that our audio-language model demonstrates a stronger recognition ability of environments over CLAP.
        </left></p>
        </div>
      </div>

      <br>
      <hr>
      <center> <h2> Acknowledgements </h2> </center>
      <p> 
        Based on a template by <a href="http://web.mit.edu/phillipi/">Phillip Isola</a> and <a href="http://richzhang.github.io/">Richard Zhang</a>.
      </p>
      <br>
<br>


</body><grammarly-desktop-integration data-grammarly-shadow-root="true"></grammarly-desktop-integration></html>
